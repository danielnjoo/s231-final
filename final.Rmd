---
title: "231_final"
author: "Margaret Chien, Amber Liu, Daniel Njoo"
date: "11/9/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```

# The Story
http://varianceexplained.org/r/trump-tweets/ inspired us to see what we could do with textual analysis of Twitter and connect it to personality types

# Abstract
Using the Twitter data set, we made clusters to see whether there were distinct personality groups and found five groups to be most workable. Then we looked at how the personality categories we had created related to Twitter presence. We looked at the number of tweets per day and total tweets, and found that ____. Then we looked at klout score, which measures popularity, followers, and friends. We then looked at the actions of these people, specifically their favorites and the type of tweets they do. We found that ___.

# Data
source: https://www.kaggle.com/c/twitter-personality-prediction, data sent in private communication with competition holder from the privacy foundation

```{r}
library(readxl)
library(tidyverse)
data<-readxl::read_xlsx('./twitter_data.xlsx')
```

587 columns, 2930 observations 
```{r}
data %>% dim()
```

18 broad categories
```{r}
names(data)[-grep("X__",names(data))]
```

# Analysis 

recreating LIWC variables requires LIWC API access from https://www.receptiviti.ai/liwc-api-get-started

no extra information on variables given due to privacy concerns https://www.kaggle.com/c/twitter-personality-prediction/discussion/1886#latest-11996

```{r}
association1 <- data[4:nrow(data),] %>% 
  sapply(., as.numeric) %>% 
  as.data.frame()
names(association1) <- data[3, ]
visualizations <- association1 %>%
  select("openness", "conscientiousness", "extraversion", "agreeableness", "Neuroticism", "Machiavellianism", "narcissism", "psychopathy", "followers_count", "statuses_count", "favourites_count", "kloutscore", "PercentOrigTweets", "PercentRT", "PercentReplies")
visualizations %>%
  ggplot(aes(x = PercentRT, y = psychopathy)) +
  geom_point() +
  geom_jitter() 
visualizations %>%
  filter(followers_count <= 5000) %>%
  filter(followers_count >= 300) %>%
  ggplot(aes(x = followers_count, y = agreeableness)) +
  geom_point() +
  geom_jitter()
visualizations %>%
  filter(statuses_count >= 3000) %>%
  ggplot(aes(y = openness, x = statuses_count)) +
  geom_point() +
  geom_jitter() 
visualizations %>%
  filter(PercentRT >= .25) %>%
  filter(statuses_count <= 10000) %>%
  ggplot(aes(x = PercentRT, y = agreeableness)) +
  geom_point() +
  geom_jitter() 
visualizations %>%
  ggplot(aes(x = PercentRT, y = openness)) +
  geom_point() +
  geom_jitter() 
visualizations %>%
  ggplot(aes(y = openness, x = log(statuses_count))) +
  geom_point() +
  geom_jitter() +
  geom_smooth()

cor(visualizations)

pairs(visualizations)

str(visualizations)

#y variables: openness, conscientiousness, extraversion, agreeableness, Neuroticism, Machiavellianism, narcissism, psychopathy
#x variables: tweets/days, total tweets, klout, followers, favorites, %retweets, %replies, %originals
```

# Methodology (proposed)

cluster (Big5/Dark3/All8) into categories, then attempt predictive models with the following variables (all of which should be recreate-able):
- tweets/days, total tweets
- klout 
- followers
- favorites
- %retweets, replies, originals

if results are reasonable, model can be used to predict new user category given data

```{r}
# create category labels based on BIG5 and NUM_CAT=5, and apply to dataset: temp
big5 <- data[4:nrow(data),2:6] %>% sapply(., as.numeric) %>% as.data.frame()
names(big5) <- data[3, 2:6]

num_cat <- 3

kmeans(big5, num_cat)$cluster %>% 
  as.data.frame() %>% 
  rbind(0,.) %>%
  rbind(0,.) %>%
  rbind(0,.) %>% 
  cbind(data) -> temp
names(temp) <- temp[3,]
names(temp)[1] <- 'cat'
```

```{r}
big5 <- data[4:nrow(data),2:6] %>% sapply(., as.numeric) %>% as.data.frame()
names(big5) <- data[3, 2:6]
pcabig5 <- big5 %>% 
  lapply(as.numeric) %>% 
  as.data.frame  %>% 
  log %>% 
  prcomp(center=T,scale=T)

plot_data <- cbind(as.data.frame(pcabig5$x[, 1:2]), labels=as.factor(kmeans(big5, 5)$cluster))
                   
plot_data %>% 
  ggplot(aes(PC1,PC2, col=labels)) +
  geom_point() 
```

```{r}
correct=0
preds<-c()

for (i in 1:100){
   
data_with_cat<-temp[4:nrow(temp),] %>% select(cat, openness, conscientiousness, Neuroticism, agreeableness, extraversion) %>% na.omit
#random row
rand <- sample(nrow(data_with_cat),1)

#take random row, calculate 100 nearest neighbors and get their ids
data_with_cat[rand,] %>% rbind(data_with_cat) %>% data.matrix %>% kNN(x=.,k=100) %>% .$id %>% head(1) -> closest_100_ids
 
#get `cat` for the 100 nearest neighbors, and find the `cat` that appears most -> pred, compare with actual
prop.table(table(data_with_cat[closest_100_ids,'cat'])) %>% 
 data.frame %>% 
 arrange(desc(Freq)) %>% 
 head(1) %>% 
 select(Var1) -> pred

data_with_cat[rand,'cat'] -> actual; print(paste0('pred is ', pred, ' actual is ', actual))

preds<-c(preds,as.numeric(pred))

if (actual==pred){correct=correct+1}

}

paste0('accuracy: ', correct/100)
prop.table(table(preds))
```


```{r}
library(randomForest)
library(caret)
set.seed(1)

temp2<-temp[4:nrow(temp),] %>% select(cat, kloutscore,followers_count,PercentOrigTweets, PercentRT,PercentReplies, AllTweetsAvg, posemo, negemo, WC)


temp2<-temp[4:nrow(temp),] %>% select(cat, kloutscore,followers_count,PercentOrigTweets, PercentRT,PercentReplies, AllTweetsAvg, posemo, negemo, WC
,WPS	,Sixltr	,Dic	,funct	,pronoun	,ppron	,i	,we	,you	,shehe	,they	,ipron	,article	,verb	,auxverb	,past	,present	,future	,adverb	,preps,	conj, negate,	quant,	number,	swear	,social	,family	,friend	,humans	,affect	,posemo	,negemo	,anx	,anger	,sad	,cogmech	,insight	,cause	,discrep	,tentat	,certain,	inhib,	incl,	excl,	percept,	see,	hear,	feel,	bio,	body,	health,	sexual,	ingest,	relativ,	motion,	space,	time,	work,	achieve,	leisure,	home,	money,	relig,	death,	assent,	nonfl,	filler,	Period,	Comma,	Colon,	SemiC,	QMark,	Exclam,	Dash,	Quote,	Apostro,	Parenth,	OtherP,	AllPct)

train_ind <- sample(seq_len(nrow(temp2)), size = floor(0.9*nrow(temp2)))
train <- temp2[train_ind,]
test <- temp2[-train_ind,]

mod <- train %>% na.omit %>% randomForest(as.factor(cat) ~ .,
                      data=., 
                      importance=TRUE, 
                      ntree=2000)
test$pred <- predict(mod, test)

confusionMatrix(test$cat,test$pred)
prop.table(table(temp2$cat))

library(nnet)
mod2 <- train %>% na.omit %>% multinom(as.factor(cat)~., data =.)


# confusionMatrix(temp2$cat,temp2$pred)
```



```{r}
tweets <- userTimeline("realDonaldTrump", n =500)
tab <- twListToDF(tweets) %>% .[!duplicated(tab[,c('text')]),]
tab2 <- tab[!duplicated(tab[,c('text')]),]
```


